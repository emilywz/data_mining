#!/usr/bin/env python3
# -*- coding:utf-8 -*- 
#Author:Emily_Wang
#evn:python3.6

import pymongo
from fake_useragent import UserAgent
from selenium import webdriver
import  time

class JDSpider(object):
    def __init__(self):
        self.url='https://www.jd.com/'
        self.options=webdriver.FirefoxOptions()
        self.options.add_argument('--headless')

        self.browser=webdriver.Firefox(options=self.options)
        self.browser.get(self.url)

        #mongodb
        self.conn=pymongo.MongoClient('localhost',27017)
        self.db=self.conn['jddb']
        self.mysite=self.db['jdset']


    def get_html(self):
        '''search goods'''
        input_node=self.browser.find_element_by_xpath('//*[@id="key"]')
        input_node.send_keys('爬虫书')
        button_node=self.browser.find_element_by_xpath('//*[@id="search"]/div/div[2]/button')
        button_node.click()
        time.sleep(5)

    def parse_html(self):
        self.browser.execute_script('window.scrollTo(0,document.body.scrollHeight)')
        # 给商品预留加载时间
        time.sleep(6)
        li_list=self.browser.find_elements_by_xpath('//*[@id="J_goodsList"]/ul/li')

        for li in li_list:
            item={}
            product_info_list=li.text.split('\n')
            if product_info_list[0].startswith('￥'):
                item['price']=product_info_list[0]
                item['book']=product_info_list[1]
                item['commit']=product_info_list[2]
                item['publisher']=product_info_list[3]
            else:
                item['price'] = product_info_list[1]
                item['book'] = product_info_list[2]
                item['commit'] = product_info_list[3]
                item['publisher'] = product_info_list[4]
            print(item)
            #save in mongodb
            self.mysite.insert_one(item)
            print('#'*50)

    def run(self):
        self.get_html()
        while True:
            self.parse_html()
            if self.browser.page_source.find('pn-next disable')==-1:
                self.browser.find_element_by_xpath('//*[@id="J_bottomPage"]/span[1]/a[9]').click()
                time.sleep(2)
            else:
                self.browser.quit()
                break



if __name__ == '__main__':
    spider=JDSpider()
    spider.run()
